{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"digits_ocr.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNzp9E7t+QS+l5CpJT/aC6X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gWi12KMvdgr1"},"source":["# Install dependencies"]},{"cell_type":"code","metadata":{"id":"-mlLCLadeEAY"},"source":["!pip install tensorflow-gpu==2.1\n","!pip install keras==2.3.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vq8d93DGoGgL"},"source":["# Connect google drive"]},{"cell_type":"code","metadata":{"id":"_CNi5r12oIou"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FS0DuRVd8WD"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"AxZrHwLodkV-","executionInfo":{"status":"ok","timestamp":1603394551090,"user_tz":-120,"elapsed":1482,"user":{"displayName":"Kacper Wachnik","photoUrl":"","userId":"11200589182507675871"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import cv2\n","from scipy import misc\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import h5py\n","\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, LSTM, Embedding, TimeDistributed, \\\n","Conv2D, MaxPooling2D, GlobalMaxPool2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from PIL import Image, ImageDraw, ImageFont\n","from keras.datasets import mnist\n","\n","import os\n","from os import path\n","import datetime\n","import random\n","from random import shuffle, randint\n","import glob\n","import shutil\n","\n","import pickle\n","import gzip"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Oi_q9qUbY9w"},"source":["# Useful commands"]},{"cell_type":"code","metadata":{"id":"LHwKChpjbX5y"},"source":["%pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNQOu93RyNS2"},"source":["# Useful constants"]},{"cell_type":"code","metadata":{"id":"BjAcbvmeyQBI","executionInfo":{"status":"ok","timestamp":1603394563064,"user_tz":-120,"elapsed":1135,"user":{"displayName":"Kacper Wachnik","photoUrl":"","userId":"11200589182507675871"}}},"source":["working_dir = \"working_dir/\"\n","\n","if not os.path.isdir(working_dir):\n","    os.mkdir(working_dir)\n","\n","vocab = ['s', '0', '1', '2', '3', '4', '5', '6',\n","            '7', '8', '9', 'e']\n","\n","ixtoword = {}\n","wordtoix = {}\n","ix = 0\n","for w in vocab:\n","    wordtoix[w] = ix\n","    ixtoword[ix] = w\n","    ix += 1\n","\n","vocab_size = len(ixtoword)\n","\n","# max length of the digit sequence\n","max_length = 6"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gArht7DsOqR4"},"source":["# Useful functions"]},{"cell_type":"code","metadata":{"id":"Aq198PT0OsBd","executionInfo":{"status":"ok","timestamp":1603394567573,"user_tz":-120,"elapsed":1728,"user":{"displayName":"Kacper Wachnik","photoUrl":"","userId":"11200589182507675871"}}},"source":["def visualize_data(images):\n","    for i in range(25):\n","        plt.subplot(5, 5, i+1)\n","        im = images[i+1]\n","        plt.imshow(im.reshape(25,50), cmap='gray')\n","        plt.axis('off')\n","\n","def encode_sequence(img, string, wordtoix):\n","    images, in_sequences, out_sequences = list(), list(), list()\n","    # encode the sequence\n","    seq = [wordtoix[char] for char in string if char in wordtoix]\n","    seq.insert(0, 0)\n","    seq.append(11)\n","    # split one sequence into multiple X, y pairs\n","    for i in range(1, len(seq)):\n","    # split into input and output pair\n","        in_seq, out_seq = seq[:i], seq[i]\n","        # pad input sequence\n","        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","        # encode output sequence\n","        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","        # store\n","        images.append(np.asarray(img))\n","        in_sequences.append(in_seq)\n","        out_sequences.append(out_seq)\n","    return np.array(images), np.array(in_sequences), np.array(out_sequences)\n","\n","def normalize_data(img_data):\n","    #Converting everything to floats\n","    img_data = img_data.astype('float32')\n","    #Normalizing values between 0 and 1\n","    img_data /= 255\n","    return img_data"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9cbKfh49tV2J"},"source":["# Load synthetic data using different fonts"]},{"cell_type":"code","metadata":{"id":"y_OgFQHLDv-I"},"source":["!7za x /mydrive/Digits_ocr/fonts.7z -oworking_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8Fue_qwtWcr"},"source":["random.seed(42)\n","\n","SAMPLES = 100000\n","fonts_path = working_dir + \"fonts\"\n","\n","def load_synthetic_data_from_fonts(samples, fonts_path):\n","\n","    X1_synt, X2_synt, y_synt = list(), list(), list()\n","    fonts_files = os.listdir(fonts_path)\n","    fonts_files_num = len(fonts_files)\n","\n","    for s in range(samples):\n","        img = None\n","        \n","        # random font\n","        font_file = random.randint(0, fonts_files_num-1)\n","        font_size = random.randint(10, 16)\n","        fnt = ImageFont.truetype('{}/{}'.format(fonts_path, fonts_files[font_file]), font_size)\n","\n","        # number of digits in number\n","        digits = randint(1,int(50/font_size))\n","\n","        # concatenate digits into number\n","        number = \"\"\n","        for j in range(digits):\n","            dgt = random.randint(0, 9)\n","            number += str(dgt)\n","\n","        grayscale_value = random.randint(0, 30)\n","        img = Image.new('L', (50, 25), color = grayscale_value)\n","\n","        # draw number\n","        start_x, start_y = random.randint(16-font_size, 18-font_size), random.randint(2, 4)\n","        d = ImageDraw.Draw(img)\n","\n","        grayscale_value = random.randint(150, 255)\n","        d.text((start_x, start_y), number, font=fnt, fill=grayscale_value)\n","\n","        img_array, in_seq, out_seq = encode_sequence(img, number, wordtoix)\n","        X1_synt.extend(img_array)\n","        X2_synt.extend(in_seq)\n","        y_synt.extend(out_seq)\n","\n","    X1_synt = np.array(X1_synt)\n","    X2_synt = np.array(X2_synt)\n","    y_synt = np.array(y_synt)\n","\n","    X1_synt = np.expand_dims(X1_synt, axis = 3)\n","\n","    return X1_synt, X2_synt, y_synt\n","\n","X1_synt_fonts, X2_synt_fonts, y_synt_fonts = load_synthetic_data_from_fonts(SAMPLES, fonts_path)\n","print(X1_synt_fonts.shape)\n","print(X2_synt_fonts.shape)\n","print(y_synt_fonts.shape)\n","\n","# normalize the data\n","X1_synt_fonts = normalize_data(X1_synt_fonts)\n","\n","# Visualize digits sequences generated\n","visualize_data(X1_synt_fonts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FEwh-1vda8TD"},"source":["# Load synthetic data using MNIST digits"]},{"cell_type":"code","metadata":{"id":"-rD-WAEbbEcp"},"source":["random.seed(42)\n","\n","def load_synthetic_data_from_mnist(samples):\n","\n","    X1_synt, X2_synt, y_synt = list(), list(), list()\n","\n","    # Load raw data from keras dataset\n","    (X_raw, y_raw), (X_raw_test, y_raw_test) = mnist.load_data()\n","    n_train, n_test = X_raw.shape[0], X_raw_test.shape[0]\n","    n_class, n_len, height, width = 11, 5, 25, 10\n","\n","    X_len = X_raw.shape[0]\n","\n","    for j in range(samples):\n","        # generate random numbers of digits\n","        img = np.zeros((height, width*n_len), dtype=np.uint8)\n","        n_digit = random.randint(1,5)\n","        number = \"\"\n","        shift_vert = random.randint(4, 12)\n","        for i in range(n_digit):\n","            index = random.randint(0, X_len-1)\n","            image = X_raw[index]\n","            image = image[3:28, 4:24]\n","            # resize image\n","            image = cv2.resize(image, (10,12))\n","            shift_hor = random.randint(0, 2) if i != 4 else 0\n","            img[shift_vert:shift_vert+12, \n","                shift_hor+i*width:shift_hor+width+i*width] = image.copy()\n","            number += str(y_raw[index])\n","\n","        img_array, in_seq, out_seq = encode_sequence(img, number, wordtoix)\n","        X1_synt.extend(img_array)\n","        X2_synt.extend(in_seq)\n","        y_synt.extend(out_seq)\n","\n","    X1_synt = np.array(X1_synt)\n","    X2_synt = np.array(X2_synt)\n","    y_synt = np.array(y_synt)\n","\n","    X1_synt = np.expand_dims(X1_synt, axis = 3)\n","\n","    return X1_synt, X2_synt, y_synt\n","\n","X1_synt_mnist, X2_synt_mnist, y_synt_mnist = load_synthetic_data_from_mnist(int(SAMPLES))\n","print(X1_synt_mnist.shape)\n","print(X2_synt_mnist.shape)\n","print(y_synt_mnist.shape)\n","\n","# normalize the data\n","X1_synt_mnist = normalize_data(X1_synt_mnist)\n","\n","# Visualize digits sequences generated\n","visualize_data(X1_synt_mnist)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qDRbHFQca6CG"},"source":["# Load real, custom data"]},{"cell_type":"code","metadata":{"id":"DjpS0N8fA_92"},"source":["!7za x /mydrive/Digits_ocr/custom_digits_sequences.7z -oworking_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rtm9CFZBa7oK"},"source":["random.seed(42)\n","\n","def load_real_data():\n","\n","    X1_real, X2_real, y_real = list(), list(), list()\n","    training_folders = os.listdir(working_dir + 'custom_digits_sequences')\n","\n","    for f in training_folders:\n","        training_files = os.listdir(working_dir + 'custom_digits_sequences/' + f)\n","        for image in training_files:\n","            path = working_dir + 'custom_digits_sequences/' + f + '/' + image\n","            im = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","            img_array, in_seq, out_seq = encode_sequence(im, f, wordtoix)\n","            X1_real.extend(img_array)\n","            X2_real.extend(in_seq)\n","            y_real.extend(out_seq)\n","\n","    X1_real = np.array(X1_real)\n","    X2_real = np.array(X2_real)\n","    y_real = np.array(y_real)\n","\n","    X1_real = np.expand_dims(X1_real, axis = 3)\n","\n","    return X1_real, X2_real, y_real\n","\n","X1_real, X2_real, y_real = load_real_data()\n","print(X1_real.shape)\n","print(X2_real.shape)\n","print(y_real.shape)\n","\n","# normalize the data\n","X1_real = normalize_data(X1_real)\n","\n","# Visualize digits sequences generated\n","visualize_data(X1_real)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LzpL2WYNLW8Y"},"source":["# Model building"]},{"cell_type":"code","metadata":{"id":"yOr_11JLLkM-"},"source":["def get_model():\n","    # input image\n","    inputs_img = tf.keras.Input(shape=(25, 50, 1))\n","\n","    # convolution model\n","    x = Conv2D(32, kernel_size=(3, 3), strides=2, \n","            padding='valid', activation='relu')(inputs_img)\n","    x = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), \n","                    padding='valid', data_format=None)(x)\n","\n","    x = Conv2D(64, kernel_size=(3, 3), strides=1, \n","            padding='valid', activation='relu')(x)\n","    x = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), \n","                    padding='valid', data_format=None)(x)\n","\n","    x = Conv2D(128, kernel_size=(3, 3), strides=1, \n","            padding='valid', activation='relu')(x)\n","    x = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), \n","                    padding='valid', data_format=None)(x)\n","\n","    # fully connected\n","    x = Flatten()(x)\n","    fe1 = Dropout(0.25)(x)\n","    fe2 = Dense(128, activation='relu')(fe1)\n","\n","    # partial caption sequence model\n","    vocab_size = 12\n","    max_length = 6\n","    embedding_dim = 50\n","\n","    inputs_seq = Input(shape=(max_length,))\n","    se1 = Embedding(vocab_size, embedding_dim)(inputs_seq) #, mask_zero=True\n","    mask = tf.keras.layers.Masking(mask_value=0)(se1)\n","    se2 = Dropout(0.5)(mask)\n","    se3 = LSTM(64)(se2)\n","\n","    # decoder (feed forward) model\n","    decoder1 = tf.keras.layers.concatenate([fe2, se3])\n","    decoder2 = Dense(64, activation='relu')(decoder1)\n","    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","\n","    # merge the two input models\n","    model = Model(inputs=[inputs_img, inputs_seq], outputs=outputs)\n","\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', \n","                metrics=['accuracy'])\n","    \n","    return model\n","\n","model = get_model()\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amcOduqq2ZOG"},"source":["# Visualize the network model using graphviz"]},{"cell_type":"code","metadata":{"id":"49MB6Lja2auf"},"source":["from tensorflow.keras.utils import plot_model, model_to_dot\n","from IPython.display import Image, SVG\n","plot_model(model, to_file='model.png', show_shapes=True)\n","Image('model.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-vNOOfyj0A4t"},"source":["# Setup TensorBoard before training"]},{"cell_type":"code","metadata":{"id":"ZHGu3Vrm0E19"},"source":["%load_ext tensorboard\n","%tensorboard --logdir working_dir/logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZtZy5xS2e8r"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"OfyFTCGJ2iMe"},"source":["random.seed(42)\n","\n","# Load the data and print its shape\n","X1 = np.concatenate((X1_synt_fonts, X1_synt_mnist, X1_real), axis=0) #, X1_real\n","X2 = np.concatenate((X2_synt_fonts, X2_synt_mnist, X2_real), axis=0) #, X2_real\n","y = np.concatenate((y_synt_fonts, y_synt_mnist, y_real), axis=0) #, y_real\n","print(X1.shape)\n","print(X2.shape)\n","print(y.shape)\n","\n","# Load existing weights\n","model.load_weights('/mydrive/Digits_ocr/model4.h5')\n","\n","# TensorBoard settings\n","log_dir = working_dir + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n","\n","# Train the neural network.\n","model.fit(\n","\t\tx=[X1, X2], y=y,\n","        epochs=20,\n","\t\tshuffle=True,\n","        validation_split=0.2,\n","\t\t#validation_data=([X1_real, X2_real], y_real),\n","\t\t#callbacks=[tensorboard_callback]\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-EdUrzbT7Tr"},"source":["# Save the model"]},{"cell_type":"code","metadata":{"id":"m0t7HPkgT-0e","executionInfo":{"status":"ok","timestamp":1603398743211,"user_tz":-120,"elapsed":926,"user":{"displayName":"Kacper Wachnik","photoUrl":"","userId":"11200589182507675871"}}},"source":["model.save_weights('/mydrive/Digits_ocr/model5.h5')"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZh1vNenmt7a"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"fEd9lESemwUg"},"source":["def greedySearch(photo):\n","    in_text = 's'\n","    for i in range(max_length):\n","        sequence = [wordtoix[w] for w in in_text if w in wordtoix]\n","        sequence = pad_sequences([sequence], maxlen=max_length)\n","        yhat = model.predict([photo,sequence], verbose=0)\n","        yhat = np.argmax(yhat)\n","        word = ixtoword[yhat]\n","        in_text += '' + word\n","        if word == 'e':\n","            break\n","    final = in_text\n","    final = final[1:-1]\n","    final = ' '.join(final)\n","    return final\n","\n","# check on synthetic data\n","image = X1_synt_fonts[100]\n","plt.imshow(image.reshape(25,50), cmap='gray')\n","plt.show()\n","\n","# prepare for the inference\n","image = image.reshape(-1, 25, 50, 1)\n","\n","if image is not None:\n","    print(\"Greedy:\", greedySearch(image))\n","else:\n","    print('Image is None')"],"execution_count":null,"outputs":[]}]}